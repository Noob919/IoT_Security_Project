{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13pUYBJkEC-6kShyiMHMcOdSw6w0T7XXb",
      "authorship_tag": "ABX9TyN7b7p50erqNfYnXgI/OtOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noob919/IoT_Security_Project/blob/main/IoT_Security_logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V9vpRkn-76yc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset directory\n",
        "DATASET_DIRECTORY = '../content/drive/MyDrive/Data/'\n",
        "\n",
        "# Importing Dataset\n",
        "\n",
        "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
        "df_sets.sort()\n",
        "training_sets = df_sets[:int(len(df_sets) * 0.8)]\n",
        "test_sets = df_sets[int(len(df_sets) * 0.8):]\n",
        "\n",
        "X_columns = [\n",
        "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
        "    'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
        "    'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
        "    'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
        "    'syn_count', 'fin_count', 'urg_count', 'rst_count',\n",
        "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
        "    'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
        "    'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
        "    'Radius', 'Covariance', 'Variance', 'Weight',\n",
        "]\n",
        "y_column = 'label'"
      ],
      "metadata": {
        "id": "JKBF8Zcs8S5h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification: 2 (1+1) classes\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for train_set in tqdm(training_sets):\n",
        "    scaler.fit(pd.read_csv(DATASET_DIRECTORY + train_set)[X_columns])\n",
        "\n",
        "dict_2classes = {}\n",
        "dict_2classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
        "dict_2classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-SYN_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-UDP_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-TCP_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
        "dict_2classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
        "dict_2classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
        "dict_2classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
        "dict_2classes['DDoS-SlowLoris'] = 'DDoS'\n",
        "dict_2classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
        "\n",
        "dict_2classes['DoS-UDP_Flood'] = 'DoS'\n",
        "dict_2classes['DoS-SYN_Flood'] = 'DoS'\n",
        "dict_2classes['DoS-TCP_Flood'] = 'DoS'\n",
        "dict_2classes['DoS-HTTP_Flood'] = 'DoS'\n",
        "\n",
        "dict_2classes['Mirai-greeth_flood'] = 'other'\n",
        "dict_2classes['Mirai-greip_flood'] = 'other'\n",
        "dict_2classes['Mirai-udpplain'] = 'other'\n",
        "\n",
        "dict_2classes['Recon-PingSweep'] = 'other'\n",
        "dict_2classes['Recon-OSScan'] = 'other'\n",
        "dict_2classes['Recon-PortScan'] = 'other'\n",
        "dict_2classes['VulnerabilityScan'] = 'other'\n",
        "dict_2classes['Recon-HostDiscovery'] = 'other'\n",
        "\n",
        "dict_2classes['DNS_Spoofing'] = 'other'\n",
        "dict_2classes['MITM-ArpSpoofing'] = 'other'\n",
        "\n",
        "dict_2classes['BenignTraffic'] = 'other'\n",
        "\n",
        "dict_2classes['BrowserHijacking'] = 'other'\n",
        "dict_2classes['Backdoor_Malware'] = 'other'\n",
        "dict_2classes['XSS'] = 'other'\n",
        "dict_2classes['Uploading_Attack'] = 'other'\n",
        "dict_2classes['SqlInjection'] = 'other'\n",
        "dict_2classes['CommandInjection'] = 'other'\n",
        "\n",
        "dict_2classes['DictionaryBruteForce'] = 'other'\n",
        "\n",
        "ML_models = [\n",
        "    LogisticRegression(n_jobs=-1),\n",
        "]\n",
        "\n",
        "ML_names = [\n",
        "    \"LogisticRegression\",\n",
        "]\n",
        "\n",
        "for train_set in tqdm(training_sets):\n",
        "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
        "    d[X_columns] = scaler.transform(d[X_columns])\n",
        "    new_y = [dict_2classes[k] for k in d[y_column]]\n",
        "    d[y_column] = new_y\n",
        "\n",
        "    for model in ML_models:\n",
        "        model.fit(d[X_columns], d[y_column])\n",
        "    del d\n",
        "\n",
        "y_test = []\n",
        "preds = {i: [] for i in range(len(ML_models))}\n",
        "for test_set in tqdm(test_sets):\n",
        "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
        "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
        "    new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
        "    d_test[y_column] = new_y\n",
        "\n",
        "    y_test += list(d_test[y_column].values)\n",
        "\n",
        "    for i in range(len(ML_models)):\n",
        "        model = ML_models[i]\n",
        "        y_pred = list(model.predict(d_test[X_columns]))\n",
        "        preds[i] = preds[i] + y_pred\n",
        "\n",
        "for k, v in preds.items():\n",
        "    y_pred = v\n",
        "    print(f\"##### {ML_names[k]} (8 classes) #####\")\n",
        "    print('accuracy_score = ', accuracy_score(y_pred, y_test))\n",
        "    print('recall_score = ', recall_score(y_pred, y_test, average='macro'))\n",
        "    print('precision_score = ', precision_score(y_pred, y_test, average='macro'))\n",
        "    print('f1_score = ', f1_score(y_pred, y_test, average='macro'))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJQcGtd59UVS",
        "outputId": "fda9d736-891f-48bd-9386-5de574351b23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [06:21<00:00,  2.83s/it]\n",
            "100%|██████████| 135/135 [31:44<00:00, 14.11s/it]\n",
            "100%|██████████| 34/34 [02:26<00:00,  4.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### LogisticRegression (8 classes) #####\n",
            "accuracy_score =  0.843560559646992\n",
            "recall_score =  0.8694509312660809\n",
            "precision_score =  0.7053377685297316\n",
            "f1_score =  0.7127350547547285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdsLZIa1lG1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}